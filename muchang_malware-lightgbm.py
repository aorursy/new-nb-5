# This Python 3 environment comes with many helpful analytics libraries installed

# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python

# For example, here's several helpful packages to load in 



import numpy as np # linear algebra

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

from sklearn.preprocessing import LabelEncoder, OneHotEncoder

from sklearn.model_selection import StratifiedKFold

from sklearn.metrics import mean_squared_error, roc_auc_score



import lightgbm as lgb

import xgboost as xgb



import matplotlib.pyplot as plt

import seaborn as sns


import plotly.offline as py

py.init_notebook_mode(connected=True)

import plotly.graph_objs as go

import plotly.tools as tls

import time



sns.set(color_codes=True)

np.random.seed(sum(map(ord, 'distributions')))



# Input data files are available in the "../input/" directory.

# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

from tqdm._tqdm_notebook import tqdm_notebook as tqdm

import os

import gc

print(os.listdir("../input"))



# Any results you write to the current directory are saved as output.
dtypes = {

        'MachineIdentifier':                                    'category',

        'ProductName':                                          'category',

        'EngineVersion':                                        'category',

        'AppVersion':                                           'category',

        'AvSigVersion':                                         'category',

        'IsBeta':                                               'int8',

        'RtpStateBitfield':                                     'float16',

        'IsSxsPassiveMode':                                     'int8',

        'DefaultBrowsersIdentifier':                            'float16',

        'AVProductStatesIdentifier':                            'float32',

        'AVProductsInstalled':                                  'float16',

        'AVProductsEnabled':                                    'float16',

        'HasTpm':                                               'int8',

        'CountryIdentifier':                                    'int16',

        'CityIdentifier':                                       'float32',

        'OrganizationIdentifier':                               'float16',

        'GeoNameIdentifier':                                    'float16',

        'LocaleEnglishNameIdentifier':                          'int8',

        'Platform':                                             'category',

        'Processor':                                            'category',

        'OsVer':                                                'category',

        'OsBuild':                                              'int16',

        'OsSuite':                                              'int16',

        'OsPlatformSubRelease':                                 'category',

        'OsBuildLab':                                           'category',

        'SkuEdition':                                           'category',

        'IsProtected':                                          'float16',

        'AutoSampleOptIn':                                      'int8',

        'PuaMode':                                              'category',

        'SMode':                                                'float16',

        'IeVerIdentifier':                                      'float16',

        'SmartScreen':                                          'category',

        'Firewall':                                             'float16',

        'UacLuaenable':                                         'float32',

        'Census_MDC2FormFactor':                                'category',

        'Census_DeviceFamily':                                  'category',

        'Census_OEMNameIdentifier':                             'float16',

        'Census_OEMModelIdentifier':                            'float32',

        'Census_ProcessorCoreCount':                            'float16',

        'Census_ProcessorManufacturerIdentifier':               'float16',

        'Census_ProcessorModelIdentifier':                      'float16',

        'Census_ProcessorClass':                                'category',

        'Census_PrimaryDiskTotalCapacity':                      'float32',

        'Census_PrimaryDiskTypeName':                           'category',

        'Census_SystemVolumeTotalCapacity':                     'float32',

        'Census_HasOpticalDiskDrive':                           'int8',

        'Census_TotalPhysicalRAM':                              'float32',

        'Census_ChassisTypeName':                               'category',

        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',

        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',

        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',

        'Census_PowerPlatformRoleName':                         'category',

        'Census_InternalBatteryType':                           'category',

        'Census_InternalBatteryNumberOfCharges':                'float32',

        'Census_OSVersion':                                     'category',

        'Census_OSArchitecture':                                'category',

        'Census_OSBranch':                                      'category',

        'Census_OSBuildNumber':                                 'int16',

        'Census_OSBuildRevision':                               'int32',

        'Census_OSEdition':                                     'category',

        'Census_OSSkuName':                                     'category',

        'Census_OSInstallTypeName':                             'category',

        'Census_OSInstallLanguageIdentifier':                   'float16',

        'Census_OSUILocaleIdentifier':                          'int16',

        'Census_OSWUAutoUpdateOptionsName':                     'category',

        'Census_IsPortableOperatingSystem':                     'int8',

        'Census_GenuineStateName':                              'category',

        'Census_ActivationChannel':                             'category',

        'Census_IsFlightingInternal':                           'float16',

        'Census_IsFlightsDisabled':                             'float16',

        'Census_FlightRing':                                    'category',

        'Census_ThresholdOptIn':                                'float16',

        'Census_FirmwareManufacturerIdentifier':                'float16',

        'Census_FirmwareVersionIdentifier':                     'float32',

        'Census_IsSecureBootEnabled':                           'int8',

        'Census_IsWIMBootEnabled':                              'float16',

        'Census_IsVirtualDevice':                               'float16',

        'Census_IsTouchEnabled':                                'int8',

        'Census_IsPenCapable':                                  'int8',

        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',

        'Wdft_IsGamer':                                         'float16',

        'Wdft_RegionIdentifier':                                'float16',

        'HasDetections':                                        'int8'

        }
traindf = pd.read_csv("../input/train.csv",dtype=dtypes,low_memory=True)
# testdf = pd.read_csv("../input/test.csv",dtype=dtypes,low_memory=True)
traindf.head()
print(len(traindf))

# print(len(testdf))
# function to plot data

def plot_categorical_feature(col, only_bars=False, top_n=10, by_touch=False):

    top_n = top_n if traindf[col].nunique() > top_n else traindf[col].nunique()

    print(f"{col} has {traindf[col].nunique()} unique values and type: {traindf[col].dtype}.")

    print(traindf[col].value_counts(normalize=True, dropna=False).head())

    if not by_touch:

        if not only_bars:

            df = traindf.groupby([col]).agg({'HasDetections': ['count', 'mean']})

            df = df.sort_values(('HasDetections', 'count'), ascending=False).head(top_n).sort_index()

            data = [go.Bar(x=df.index, y=df['HasDetections']['count'].values, name='counts'),

                    go.Scatter(x=df.index, y=df['HasDetections']['mean'], name='Detections rate', yaxis='y2')]



            layout = go.Layout(dict(title = f"Counts of {col} by top-{top_n} categories and mean target value",

                                xaxis = dict(title = f'{col}',

                                             showgrid=False,

                                             zeroline=False,

                                             showline=False,),

                                yaxis = dict(title = 'Counts',

                                             showgrid=False,

                                             zeroline=False,

                                             showline=False,),

                                yaxis2=dict(title='Detections rate', overlaying='y', side='right')),

                           legend=dict(orientation="v"))



        else:

            top_cat = list(traindf[col].value_counts(dropna=False).index[:top_n])

            df0 = traindf.loc[(traindf[col].isin(top_cat)) & (traindf['HasDetections'] == 1), col].value_counts().head(10).sort_index()

            df1 = traindf.loc[(traindf[col].isin(top_cat)) & (traindf['HasDetections'] == 0), col].value_counts().head(10).sort_index()

            data = [go.Bar(x=df0.index, y=df0.values, name='Has Detections'),

                    go.Bar(x=df1.index, y=df1.values, name='No Detections')]



            layout = go.Layout(dict(title = f"Counts of {col} by top-{top_n} categories",

                                xaxis = dict(title = f'{col}',

                                             showgrid=False,

                                             zeroline=False,

                                             showline=False,),

                                yaxis = dict(title = 'Counts',

                                             showgrid=False,

                                             zeroline=False,

                                             showline=False,),

                                ),

                           legend=dict(orientation="v"), barmode='group')

        

        py.iplot(dict(data=data, layout=layout))

        

    else:

        top_n = 10

        top_cat = list(traindf[col].value_counts(dropna=False).index[:top_n])

        df = traindf.loc[traindf[col].isin(top_cat)]



        df1 = traindf.loc[traindf['Census_IsTouchEnabled'] == 1]

        df0 = traindf.loc[traindf['Census_IsTouchEnabled'] == 0]



        df0_ = df0.groupby([col]).agg({'HasDetections': ['count', 'mean']})

        df0_ = df0_.sort_values(('HasDetections', 'count'), ascending=False).head(top_n).sort_index()

        df1_ = df1.groupby([col]).agg({'HasDetections': ['count', 'mean']})

        df1_ = df1_.sort_values(('HasDetections', 'count'), ascending=False).head(top_n).sort_index()

        data1 = [go.Bar(x=df0_.index, y=df0_['HasDetections']['count'].values, name='Nontouch device counts'),

                go.Scatter(x=df0_.index, y=df0_['HasDetections']['mean'], name='Detections rate for nontouch devices', yaxis='y2')]

        data2 = [go.Bar(x=df1_.index, y=df1_['HasDetections']['count'].values, name='Touch device counts'),

                go.Scatter(x=df1_.index, y=df1_['HasDetections']['mean'], name='Detections rate for touch devices', yaxis='y2')]



        layout = go.Layout(dict(title = f"Counts of {col} by top-{top_n} categories for nontouch devices",

                            xaxis = dict(title = f'{col}',

                                         showgrid=False,

                                         zeroline=False,

                                         showline=False,

                                         type='category'),

                            yaxis = dict(title = 'Counts',

                                         showgrid=False,

                                         zeroline=False,

                                         showline=False,),

                                    yaxis2=dict(title='Detections rate', overlaying='y', side='right'),

                            ),

                       legend=dict(orientation="v"), barmode='group')



        py.iplot(dict(data=data1, layout=layout))

        layout['title'] = f"Counts of {col} by top-{top_n} categories for touch devices"

        py.iplot(dict(data=data2, layout=layout))
missing_state = []



for col in traindf.columns:

    missing_state.append((col,traindf[col].nunique(),traindf[col].isnull().sum()*100/traindf[col].shape[0],

                          traindf[col].value_counts(normalize=True, dropna=False).values[0],traindf[col].dtype))

stats_df = pd.DataFrame(missing_state, 

    columns=['Feature', 'Unique_values', 'Percentage of missing values', 'Percentage of values in the biggest category', 'type'])



stats_df.sort_values('Percentage of missing values', ascending=False)
col_list = list(traindf.columns)

for col in traindf.columns:

    rate = traindf[col].value_counts(normalize=True, dropna=False).values[0]

    if rate>0.9:

        col_list.remove(col)



traindf = traindf[col_list]
# testdf = testdf[[col for col in col_list if col not in ['HasDetections']]]

del stats_df,missing_state,col_list
# target is balance

traindf['HasDetections'].value_counts()
# for usecol in traindf.columns.tolist()[1:-1]:

# agg_tr = (traindf

#           .groupby(['Wdft_RegionIdentifier'])

#           .aggregate({'MachineIdentifier':'count'})

#           .reset_index()

#           .rename({'MachineIdentifier':'Train'}, axis=1))



# agg_te = (testdf.groupby(['Wdft_RegionIdentifier'])

#          .aggregate({'MachineIdentifier':'count'})

#          .reset_index()

#          .rename({'MachineIdentifier':'Test'},axis=1))

    
def reduce_mem_usage(df, verbose=True):

    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']

    start_mem = df.memory_usage(deep=True).sum() / 1024**2    

    for col in df.columns:

        col_type = df[col].dtypes

        if col_type in numerics:

            c_min = df[col].min()

            c_max = df[col].max()

            if str(col_type)[:3] == 'int':

                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:

                    df[col] = df[col].astype(np.int8)

                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:

                    df[col] = df[col].astype(np.int16)

                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:

                    df[col] = df[col].astype(np.int32)

                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:

                    df[col] = df[col].astype(np.int64)  

            else:

                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:

                    df[col] = df[col].astype(np.float16)

                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:

                    df[col] = df[col].astype(np.float32)

                else:

                    df[col] = df[col].astype(np.float64)    

    end_mem = df.memory_usage(deep=True).sum() / 1024**2

    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))

    return df
# plot_categorical_feature('Census_IsTouchEnabled', True)
# plot_categorical_feature('EngineVersion', by_touch=True)
# plot_categorical_feature('AppVersion',True)
# plot_categorical_feature('Census_OSEdition',True)
traindf['Census_OSEdition'].value_counts()
# agg = pd.merge(agg_tr, agg_te, on='Wdft_RegionIdentifier', how='outer')

# agg = agg[(agg['Train'] > 1000)].reset_index(drop=True)

# agg['Total'] = agg['Train'] + agg['Test']

# agg = agg[(agg['Train'] / agg['Total'] > 0.2) & (agg['Train'] / agg['Total'] < 0.8)]
traindf['OsBuildLab'] = traindf['OsBuildLab'].cat.add_categories(['0.0.0.0.0-0'])

traindf['OsBuildLab'] = traindf['OsBuildLab'].fillna('0.0.0.0.0-0')

# testdf['OsBuildLab'] = testdf['OsBuildLab'].cat.add_categories(['0.0.0.0.0-0'])

# testdf['OsBuildLab'] = testdf['OsBuildLab'].fillna('0.0.0.0.0-0')
def features(df):

    df['EngineVersion_2'] = df['EngineVersion'].apply(lambda x: x.split('.')[2]).astype('category')

    df['EngineVersion_3'] = df['EngineVersion'].apply(lambda x: x.split('.')[3]).astype('category')



    df['AppVersion_1'] = df['AppVersion'].apply(lambda x: x.split('.')[1]).astype('category')

    df['AppVersion_2'] = df['AppVersion'].apply(lambda x: x.split('.')[2]).astype('category')

    df['AppVersion_3'] = df['AppVersion'].apply(lambda x: x.split('.')[3]).astype('category')



    df['AvSigVersion_0'] = df['AvSigVersion'].apply(lambda x: x.split('.')[0]).astype('category')

    df['AvSigVersion_1'] = df['AvSigVersion'].apply(lambda x: x.split('.')[1]).astype('category')

    df['AvSigVersion_2'] = df['AvSigVersion'].apply(lambda x: x.split('.')[2]).astype('category')



    df['OsBuildLab_0'] = df['OsBuildLab'].apply(lambda x: x.split('.')[0]).astype('category')

    df['OsBuildLab_1'] = df['OsBuildLab'].apply(lambda x: x.split('.')[1]).astype('category')

    df['OsBuildLab_2'] = df['OsBuildLab'].apply(lambda x: x.split('.')[2]).astype('category')

    df['OsBuildLab_3'] = df['OsBuildLab'].apply(lambda x: x.split('.')[3]).astype('category')



    df['Census_OSVersion_0'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[0]).astype('category')

    df['Census_OSVersion_1'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[1]).astype('category')

    df['Census_OSVersion_2'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[2]).astype('category')

    df['Census_OSVersion_3'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[3]).astype('category')



    df['primary_drive_c_ratio'] = df['Census_SystemVolumeTotalCapacity']/ df['Census_PrimaryDiskTotalCapacity']

    df['non_primary_drive_MB'] = df['Census_PrimaryDiskTotalCapacity'] - df['Census_SystemVolumeTotalCapacity']



    df['aspect_ratio'] = df['Census_InternalPrimaryDisplayResolutionHorizontal']/ df['Census_InternalPrimaryDisplayResolutionVertical']



    df['monitor_dims'] = df['Census_InternalPrimaryDisplayResolutionHorizontal'].astype(str) + '*' + df['Census_InternalPrimaryDisplayResolutionVertical'].astype('str')

    df['monitor_dims'] = df['monitor_dims'].astype('category')



    df['dpi'] = ((df['Census_InternalPrimaryDisplayResolutionHorizontal']**2 + df['Census_InternalPrimaryDisplayResolutionVertical']**2)**.5)/(df['Census_InternalPrimaryDiagonalDisplaySizeInInches'])



    df['dpi_square'] = df['dpi'] ** 2



    df['MegaPixels'] = (df['Census_InternalPrimaryDisplayResolutionHorizontal'] * df['Census_InternalPrimaryDisplayResolutionVertical'])/1e6



    df['Screen_Area'] = (df['aspect_ratio']* (df['Census_InternalPrimaryDiagonalDisplaySizeInInches']**2))/(df['aspect_ratio']**2 + 1)



    df['ram_per_processor'] = df['Census_TotalPhysicalRAM']/ df['Census_ProcessorCoreCount']



    df['new_num_0'] = df['Census_InternalPrimaryDiagonalDisplaySizeInInches'] / df['Census_ProcessorCoreCount']



    df['new_num_1'] = df['Census_ProcessorCoreCount'] * df['Census_InternalPrimaryDiagonalDisplaySizeInInches']

    

    # fillna with 1 made the data more balance

    df['Census_IsFlightingInternal'] = df['Census_IsFlightingInternal'].fillna(1)

    df['Census_ThresholdOptIn'] = df['Census_ThresholdOptIn'].fillna(1)

    df['Census_IsWIMBootEnabled'] = df['Census_IsWIMBootEnabled'].fillna(1)

    df['Wdft_IsGamer'] = df['Wdft_IsGamer'].fillna(0)

    

    return df  
traindf = features(traindf)

# testdf = features(testdf)

traindf = reduce_mem_usage(traindf)

# testdf = reduce_mem_usage(testdf)
traindf.head()
traindf = traindf.sample(n=4000000)
y = traindf['HasDetections']
print(len(traindf))
cat_cols = [col for col in traindf.columns if col not in ['MachineIdentifier', 'Census_SystemVolumeTotalCapacity', 'HasDetections'] and str(traindf[col].dtype) == 'category']

print(len(cat_cols))
#Fit LabelEncoder

for usecol in cat_cols:

    

    traindf[usecol] = traindf[usecol].astype('str')

    le = LabelEncoder().fit(

            np.unique(traindf[usecol].unique().tolist()))

    

    traindf[usecol] = le.transform(traindf[usecol])+1

    

    del le

    gc.collect()
traindf.head()
reduce_mem_usage(traindf)

# testdf.reduce_mem_usage(testdf)
n_fold = 5

folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=15)
from numba import jit

# fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013

@jit

def fast_auc(y_true, y_prob):

    y_true = np.asarray(y_true)

    y_true = y_true[np.argsort(y_prob)]

    nfalse = 0

    auc = 0

    n = len(y_true)

    for i in range(n):

        y_i = y_true[i]

        nfalse += (1 - y_i)

        auc += y_i * nfalse

    auc /= (nfalse * (n - nfalse))

    return auc



def eval_auc(preds, dtrain):

    labels = dtrain.get_label()

    return 'auc', fast_auc(labels, preds), True





def train_model(X=traindf, y=y, params=None, folds=folds, model_type='lgb', plot_feature_importance=False, 

                averaging='usual', make_oof=False):

    

    result_dict = {}

    if make_oof:

        oof = np.zeros(len(X))

#     prediction = np.zeros(len(X_test))

    scores = []

    feature_importance = pd.DataFrame()

    # 5 fold 

    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):

        gc.collect()

        print('Fold', fold_n + 1, 'started at', time.ctime())

        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]

        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]

        

        print(len(train_index),len(valid_index))

        if model_type == 'lgb':

            train_data = lgb.Dataset(X_train, label=y_train, categorical_feature = cat_cols)

            valid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature = cat_cols)

            

            model = lgb.train(params,

                    train_data,

                    num_boost_round=2000,

                    valid_sets = [train_data,valid_data],

                    verbose_eval=500,

                    early_stopping_rounds = 200,

                    feval=eval_auc)



            del train_data, valid_data

            

            y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)

#             print(len(y_pred_valid))

#             print(y_valid)

            del X_valid

            gc.collect()

            # print('predicting on test')

            # y_pred = model.predict(X_test, num_iteration=model.best_iteration)

#             y_pred = predict_chunk(model, X_test)

            # print('predicted')

            

        if model_type == 'xgb':

            train_data = xgb.DMatrix(data=X_train, label=y_train)

            valid_data = xgb.DMatrix(data=X_valid, label=y_valid)



            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]

            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)

            y_pred_valid = model.predict(xgb.DMatrix(X_valid), ntree_limit=model.best_ntree_limit)

            #y_pred = model.predict(xgb.DMatrix(X_test), ntree_limit=model.best_ntree_limit)

#             y_pred = predict_chunk(model, xgb.DMatrix(X_test))

            

        if model_type == 'lcv':

            model = LogisticRegressionCV(scoring='roc_auc', cv=3)

            model.fit(X_train, y_train)



            y_pred_valid = model.predict(X_valid)

            # y_pred = model.predict(X_test)

#             y_pred = predict_chunk(model, X_test)

            

        if model_type == 'cat':

            model = CatBoostRegressor(iterations=20000,  eval_metric='AUC', **params)

            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)



            y_pred_valid = model.predict(X_valid)

            # y_pred = model.predict(X_test)

#             y_pred = predict_chunk(model, X_test)

        

        if make_oof:

            oof[valid_index] = y_pred_valid.reshape(-1,)

            

#         print(y_valid)

        score = fast_auc(y_valid,y_pred_valid)

        scores.append(score)

        print('Fold roc_auc:', roc_auc_score(y_valid, y_pred_valid))

        print('')

        

#         if averaging == 'usual':

#             prediction += y_pred

#         elif averaging == 'rank':

#             prediction += pd.Series(y_pred).rank().values

        

        if model_type == 'lgb':

            # feature importance

            fold_importance = pd.DataFrame()

            fold_importance["feature"] = X.columns

            fold_importance["importance"] = model.feature_importance()

            fold_importance["fold"] = fold_n + 1

            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)



#     prediction /= n_fold

    

    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))

    

    if model_type == 'lgb':

        

        if plot_feature_importance:

            feature_importance["importance"] /= n_fold

            cols = feature_importance[["feature", "importance"]].groupby("feature").mean().sort_values(

                by="importance", ascending=False)[:50].index



            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]

#             logging.info('Top features')

#             for f in best_features.sort_values(by="importance", ascending=False)['feature'].values:

#                 logging.info(f)



            plt.figure(figsize=(16, 12));

            sns.barplot(x="importance", y="feature", data=best_features.sort_values(by="importance", ascending=False));

            plt.title('LGB Features (avg over folds)');

            

            result_dict['feature_importance'] = feature_importance

            

#     result_dict['prediction'] = prediction

    if make_oof:

        result_dict['oof'] = oof

    

    return result_dict
# params

params = {'num_leaves': 256,

         'min_data_in_leaf': 42,

         'objective': 'binary',

         'max_depth': 8,

         'learning_rate': 0.05,

         "boosting": "gbdt",

         "feature_fraction": 0.8,

         "bagging_freq": 5,

         "bagging_fraction": 0.8,

         "bagging_seed": 11,

         "lambda_l1": 0.15,

         "lambda_l2": 0.15,

         "random_state": 42,          

         "verbosity": -1}
# traindf.head()

traindf = traindf.drop(['HasDetections', 'MachineIdentifier'], axis=1)
gc.collect()
y.head()
train_model(X=traindf, y=y, params=params, model_type='lgb', plot_feature_importance=True, averaging='rank')