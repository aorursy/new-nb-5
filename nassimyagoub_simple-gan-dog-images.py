import numpy as np

import os 

import tensorflow as tf 

import matplotlib.pyplot as plt

import cv2

import glob



import warnings

warnings.filterwarnings("ignore")



import keras

from keras.optimizers import Adam

from keras.models import Sequential, Model

from keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input

from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Conv2DTranspose
def list_images(basePath, contains=None):

    # return the set of files that are valid

    return list_files(basePath, validExts=(".jpg", ".jpeg", ".png", ".bmp"), contains=contains)



def list_files(basePath, validExts=(".jpg", ".jpeg", ".png", ".bmp"), contains=None):

    # loop over the directory structure

    for (rootDir, dirNames, filenames) in os.walk(basePath):

        # loop over the filenames in the current directory

        for filename in filenames:

            # if the contains string is not none and the filename does not contain

            # the supplied string, then ignore the file

            if contains is not None and filename.find(contains) == -1:

                continue



            # determine the file extension of the current file

            ext = filename[filename.rfind("."):].lower()



            # check to see if the file is an image and should be processed

            if ext.endswith(validExts):

                # construct the path to the image and yield it

                imagePath = os.path.join(rootDir, filename).replace(" ", "\\ ")

                yield imagePath

                

def load_images(directory='', size=(64,64)):

    images = []

    labels = []  # Integers corresponding to the categories in alphabetical order

    label = 0

    

    imagePaths = list(list_images(directory))

    

    for path in imagePaths:

        

        if not('OSX' in path):

        

            path = path.replace('\\','/')



            image = cv2.imread(path) #Reading the image with OpenCV

            image = cv2.resize(image,size) #Resizing the image, in case some are not of the same size



            images.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    

    return images
images=load_images('../input', size = (64,64))
_,ax = plt.subplots(3,3, figsize = (15,15)) 

for i in range(3):

    for j in range(3):

        ax[i,j].imshow(images[5*i+j])

        ax[i,j].axis('off')
class GAN():

    def __init__(self):

        self.img_shape = (64, 64, 3)

        

        self.noise_size = 100



        optimizer = Adam(0.0002,0.5)



        self.discriminator = self.build_discriminator()

        self.discriminator.compile(loss='binary_crossentropy', 

                                   optimizer=optimizer,

                                   metrics=['accuracy'])



        self.generator = self.build_generator()

        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)

        

        self.combined = Sequential()

        self.combined.add(self.generator)

        self.combined.add(self.discriminator)

        

        self.discriminator.trainable = False

        

        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)

        

        self.combined.summary()

        

    # Creating the generator, the large kernels in the convolutional layers allow the network to create complex structures.

    def build_generator(self):

        epsilon = 0.00001 # Small float added to variance to avoid dividing by zero in the BatchNorm layers.

        noise_shape = (self.noise_size,)

        

        model = Sequential()

        

        model.add(Dense(4*4*512, activation='linear', input_shape=noise_shape))

        model.add(LeakyReLU(alpha=0.2))

        model.add(Reshape((4, 4, 512)))

        

        model.add(Conv2DTranspose(512, kernel_size=[5,5], strides=[2,2], padding="same",

                                  kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))

        model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))

        model.add(LeakyReLU(alpha=0.2))

        

        model.add(Conv2DTranspose(256, kernel_size=[5,5], strides=[2,2], padding="same",

                                  kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))

        model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))

        model.add(LeakyReLU(alpha=0.2))

        

        model.add(Conv2DTranspose(128, kernel_size=[5,5], strides=[2,2], padding="same",

                                  kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))

        model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))

        model.add(LeakyReLU(alpha=0.2))

        

        model.add(Conv2DTranspose(64, kernel_size=[5,5], strides=[2,2], padding="same",

                                  kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))

        model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))

        model.add(LeakyReLU(alpha=0.2))

        

        model.add(Conv2DTranspose(3, kernel_size=[5,5], strides=[1,1], padding="same",

                                  kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))



        # Standard activation for the generator of a GAN

        model.add(Activation("tanh"))

        

        model.summary()



        noise = Input(shape=noise_shape)

        img = model(noise)



        return Model(noise, img)



    def build_discriminator(self):



        model = Sequential()



        model.add(Conv2D(64, (3,3), padding='same', input_shape=self.img_shape))

        model.add(LeakyReLU(alpha=0.2))

        model.add(BatchNormalization())

        model.add(Conv2D(64, (3,3), padding='same'))

        model.add(LeakyReLU(alpha=0.2))

        model.add(BatchNormalization())

        model.add(MaxPooling2D(pool_size=(3,3)))

        model.add(Dropout(0.2))



        model.add(Conv2D(128, (3,3), padding='same'))

        model.add(LeakyReLU(alpha=0.2))

        model.add(BatchNormalization())

        model.add(Conv2D(128, (3,3), padding='same'))

        model.add(LeakyReLU(alpha=0.2))

        model.add(BatchNormalization())

        model.add(MaxPooling2D(pool_size=(3,3)))

        model.add(Dropout(0.3))



        model.add(Flatten())

        model.add(Dense(128))

        model.add(LeakyReLU(alpha=0.2))

        model.add(Dense(128))

        model.add(LeakyReLU(alpha=0.2))

        model.add(Dense(1, activation='sigmoid'))

        

        model.summary()

        

        img = Input(shape=self.img_shape)

        validity = model(img)



        return Model(img, validity)



    def train(self, epochs, batch_size=128, save_images=100, save_model=2000):



        X_train = np.array(images)

        X_train = (X_train.astype(np.float32) - 127.5) / 127.5



        half_batch = int(batch_size / 2)



        for epoch in range(epochs):

            idx = np.random.randint(0, X_train.shape[0], half_batch)

            imgs = X_train[idx]



            noise = np.random.normal(0, 1, (half_batch, self.noise_size))

            gen_imgs = self.generator.predict(noise)



            # Training the discriminator

            

            # The loss of the discriminator is the mean of the losses while training on authentic and fake images

            d_loss = 0.5 * np.add(self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1))),

                                  self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1))))



            # Training the generator



            noise = np.random.normal(0, 1, (batch_size, self.noise_size))



            valid_y = np.array([1] * batch_size)

            g_loss = self.combined.train_on_batch(noise, valid_y)

            

            

            # We print the losses and accuracy of the networks every 10 batches mainly to make sure the accuracy of the discriminator

            # is not stable at around 50% or 100% (which would mean the discriminator performs not well enough or too well)

            if epoch % 30 == 0:

              print ("%d [Discriminator loss: %f, acc.: %.2f%%] [Generator loss: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss))



            if epoch % save_images == 0:

                self.save_images(epoch)

            

            # We save the architecture of the model, the weights and the state of the optimizer

            # This way we can restart the training exactly where we stopped

            if epoch % save_model == 0:

                self.generator.save("generator_%d" % epoch)

                self.discriminator.save("discriminator_%d" % epoch)



    # Saving 25 generated images to have a representation of the spectrum of images created by the generator

    def save_images(self, epoch):

        noise = np.random.normal(0, 1, (25, self.noise_size))

        gen_imgs = self.generator.predict(noise)

        

        # Rescale from [-1,1] into [0,1]

        gen_imgs = 0.5 * gen_imgs + 0.5



        fig, axs = plt.subplots(5,5, figsize = (8,8))

        c = 0

        for i in range(5):

            for j in range(5):

                axs[i,j].imshow(gen_imgs[c])

                axs[i,j].axis('off')

                c += 1



        plt.show()

        

        fig.savefig("Generated/Dogs_%d.png" % epoch)

        plt.close()
gan = GAN()

gan.train(epochs = 20001, batch_size = 128, save_images=500, save_model=100000)
import zipfile

from PIL import Image



z = zipfile.PyZipFile('images.zip', mode='w')



for k in range(10000):

    # GENERATE NEW DOGS

    noise = np.random.normal(0, 1, (1, 100))

    img = gan.generator.predict(noise)

    # Rescale from [-1,1] into [0,1]

    img = 0.5 * img + 0.5

    img = Image.fromarray( (255*img).astype('uint8').reshape((64,64,3)))

    # SAVE TO ZIP FILE  

    f = str(k)+'.png'

    img.save(f,'PNG'); z.write(f); os.remove(f)

    #if k % 1000==0: print(k)

z.close()