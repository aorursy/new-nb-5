# This Python 3 environment comes with many helpful analytics libraries installed

# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python

# For example, here's several helpful packages to load in 



import numpy as np # linear algebra

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import numpy as np

from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier

from sklearn.tree import DecisionTreeClassifier

from sklearn import preprocessing, svm, neighbors

from sklearn.linear_model import LogisticRegression

from sklearn.metrics import roc_auc_score

from sklearn import metrics

from sklearn.model_selection import StratifiedKFold

from sklearn import svm



# Input data files are available in the "../input/" directory.

# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os

print(os.listdir("../input"))



# Any results you write to the current directory are saved as output.
# 

selectedFeatures = [  

    'AVProductStatesIdentifier'

    ,'AVProductsEnabled'

    ,'IsProtected'

    ,'Processor'

    ,'OsSuite'

    ,'IsProtected'

    ,'RtpStateBitfield'

    ,'AVProductsInstalled'

    ,'Wdft_IsGamer'

    ,'DefaultBrowsersIdentifier'

    ,'OsBuild'

    ,'Wdft_RegionIdentifier'

    ,'SmartScreen'

    ,'CityIdentifier'

    ,'AppVersion'

    ,'Census_IsSecureBootEnabled'

    ,'Census_PrimaryDiskTypeName'

    ,'Census_SystemVolumeTotalCapacity'

    ,'Census_HasOpticalDiskDrive'

    ,'Census_IsWIMBootEnabled'

    ,'Census_IsVirtualDevice'

    ,'Census_IsTouchEnabled'

    ,'Census_FirmwareVersionIdentifier'

    ,'GeoNameIdentifier'

    ,'IeVerIdentifier'

    ,'Census_FirmwareManufacturerIdentifier'

    ,'Census_InternalPrimaryDisplayResolutionHorizontal'

    ,'Census_InternalPrimaryDisplayResolutionVertical'

    ,'Census_OEMModelIdentifier'

    ,'Census_ProcessorModelIdentifier'

    ,'Census_OSVersion'

    ,'Census_InternalPrimaryDiagonalDisplaySizeInInches'

    ,'Census_OEMNameIdentifier'

    ,'Census_ChassisTypeName'

    ,'Census_OSInstallLanguageIdentifier'

    ,'EngineVersion'

    ,'OrganizationIdentifier' 

    ,'CountryIdentifier'   

    ,'Census_ActivationChannel'

    ,'Census_ProcessorCoreCount'

    ,'Census_OSWUAutoUpdateOptionsName'

    ,'Census_InternalBatteryType'

    ]
import random

numberOfRows = 1000000



seed = 6001

np.random.seed(seed)

random.seed(seed)
# Load train and test files

train_file=pd.read_csv("../input/train.csv", sep=",", usecols = selectedFeatures+['HasDetections'], low_memory=True, nrows = numberOfRows)

test_file=pd.read_csv("../input/test.csv", sep=",", usecols = selectedFeatures, low_memory=True, nrows = numberOfRows)



print('Train : ' + str(train_file.shape))

print('Test : ' + str(test_file.shape))
# Check if the data contains null values

train_file.isna().sum()
df = pd.DataFrame(train_file)

df_test = pd.DataFrame(test_file)



# Drop the columns which have large amount of null values. For e.g. DefaultBrowsersIdentifier has more 900000 null values. 

# Filling it with mean or 0 will bias our model



df= df.drop(['DefaultBrowsersIdentifier', 'Census_InternalBatteryType','Census_IsWIMBootEnabled'], axis=1)

df.dtypes
# Drop all the Nan data rows

df = df.dropna()

df.describe()
labels = pd.DataFrame(df['HasDetections'])

print('Labels : ' + str(labels.shape))

df = df.drop(['HasDetections'], axis =1)

print('Train : ' + str(df.shape))
# Check count of the labels

import seaborn as sns

ax = sns.countplot(x="HasDetections", data=labels)
df.describe()
# Tune SmartScreen feature



df.loc[df.SmartScreen == 'off', 'SmartScreen']= 'Off'

df.loc[df.SmartScreen == 'of', 'SmartScreen'] = 'Off'

df.loc[df.SmartScreen == 'OFF', 'SmartScreen'] = 'Off'

df.loc[df.SmartScreen == '00000000', 'SmartScreen'] = 'Off'

df.loc[df.SmartScreen == '0', 'SmartScreen'] = 'Off'       

df.loc[df.SmartScreen == 'ON', 'SmartScreen'] = 'On'

df.loc[df.SmartScreen == 'on', 'SmartScreen'] = 'On'

df.loc[df.SmartScreen == 'Enabled', 'SmartScreen'] = 'On'

df.loc[df.SmartScreen == 'BLOCK', 'SmartScreen'] = 'Block'

df.loc[df.SmartScreen == 'requireadmin', 'SmartScreen'] = 'RequireAdmin'

df.loc[df.SmartScreen == 'requireAdmin', 'SmartScreen'] = 'RequireAdmin'

df.loc[df.SmartScreen == 'RequiredAdmin', 'SmartScreen'] = 'RequireAdmin'

df.loc[df.SmartScreen == 'Promt', 'SmartScreen'] = 'Prompt'

df.loc[df.SmartScreen == 'Promprt', 'SmartScreen'] = 'Prompt'

df.loc[df.SmartScreen == 'prompt', 'SmartScreen'] = 'Prompt'

df.loc[df.SmartScreen == 'warn', 'SmartScreen'] = 'Warn'

df.loc[df.SmartScreen == 'Deny', 'SmartScreen'] = 'Block'

df.loc[df.SmartScreen == '&#x03;', 'SmartScreen'] = 'Off'

df_test.loc[df_test.SmartScreen == 'off', 'SmartScreen'] = 'Off'

df_test.loc[df_test.SmartScreen == 'of', 'SmartScreen'] = 'Off'

df_test.loc[df_test.SmartScreen == 'OFF', 'SmartScreen'] = 'Off'

df_test.loc[df_test.SmartScreen == '00000000', 'SmartScreen'] = 'Off'

df_test.loc[df_test.SmartScreen == '0', 'SmartScreen'] = 'Off'       

df_test.loc[df_test.SmartScreen == 'ON', 'SmartScreen'] = 'On'

df_test.loc[df_test.SmartScreen == 'on', 'SmartScreen'] = 'On'

df_test.loc[df_test.SmartScreen == 'Enabled', 'SmartScreen'] = 'On'

df_test.loc[df_test.SmartScreen == 'BLOCK', 'SmartScreen'] = 'Block'

df_test.loc[df_test.SmartScreen == 'requireadmin', 'SmartScreen'] = 'RequireAdmin'

df_test.loc[df_test.SmartScreen == 'requireAdmin', 'SmartScreen'] = 'RequireAdmin'

df_test.loc[df_test.SmartScreen == 'RequiredAdmin', 'SmartScreen'] = 'RequireAdmin'

df_test.loc[df_test.SmartScreen == 'Promt', 'SmartScreen'] = 'Prompt'

df_test.loc[df_test.SmartScreen == 'Promprt', 'SmartScreen'] = 'Prompt'

df_test.loc[df_test.SmartScreen == 'prompt', 'SmartScreen'] = 'Prompt'

df_test.loc[df_test.SmartScreen == 'warn', 'SmartScreen'] = 'Warn'

df_test.loc[df_test.SmartScreen == 'Deny', 'SmartScreen'] = 'Block'

df_test.loc[df_test.SmartScreen == '&#x03;', 'SmartScreen'] = 'Off'
# Create dummy variables



dfDummy = pd.get_dummies(df, dummy_na=True)

print('Dummy: ' + str(dfDummy.shape))
train = dfDummy[:numberOfRows]

test = dfDummy[numberOfRows:]

print('== Dataset Columns ==')

features = [f for f in train.columns if f not in ['index']]

for feature in features:

    print(feature)
oofPreds = np.zeros(train.shape[0])

subPreds = np.zeros(test.shape[0])

featureImportanceDf = pd.DataFrame()

# Train LightGBM Classifier with StratifiedKFold to improve training model



from lightgbm import LGBMClassifier

from sklearn.metrics import roc_auc_score, roc_curve

from sklearn.model_selection import StratifiedKFold



folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)

for n_fold, (trainXId, validXId) in enumerate(folds.split(train[features], labels)):

    # Create TrainXY and ValidationXY set based on fold-indexes

    trainX, trainY = train[features].iloc[trainXId], labels.iloc[trainXId]

    validX, validY = train[features].iloc[validXId], labels.iloc[validXId]



    print('== Fold: ' + str(n_fold))



    # LightGBM parameters

    lgbm = LGBMClassifier(

        objective = 'binary',

        boosting_type = 'gbdt',

        n_estimators = 2500,

        learning_rate = 0.05, 

        num_leaves = 250,

        min_data_in_leaf = 125, 

        bagging_fraction = 0.901,

        max_depth = 13, 

        reg_alpha = 2.5,

        reg_lambda = 2.5,

        min_split_gain = 0.0001,

        min_child_weight = 25,

        feature_fraction = 0.5, 

        silent = -1,

        verbose = -1,

        n_jobs = -1) 



    lgbm.fit(trainX, trainY, 

        eval_set=[(trainX, trainY), (validX, validY)], 

        eval_metric = 'auc', 

        verbose = 250, 

        early_stopping_rounds = 5)



    oofPreds[validXId] = lgbm.predict_proba(validX, num_iteration = lgbm.best_iteration_)[:, 1]

    

    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(validY, oofPreds[validXId])))

          

    